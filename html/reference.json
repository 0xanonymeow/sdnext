{
  "RunwayML SD 1.5": {
    "path": "runwayml/stable-diffusion-v1-5",
    "preview": "runwayml--stable-diffusion-v1-5.jpg"
  },
  "StabilityAI SD 2.1": {
    "path": "stabilityai/stable-diffusion-2-1-base",
    "preview": "stabilityai--stable-diffusion-2.1-base.jpg"
  },
  "StabilityAI SD-XL 1.0 Base": {
    "path": "stabilityai/stable-diffusion-xl-base-1.0",
    "preview": "stabilityai--stable-diffusion-xl-base-1.0.jpg"
  },
  "Segmind SSD-1B": {
    "path": "segmind/SSD-1B",
    "preview": "segmind--ssd-1b.jpg"
  },
  "Segmind Tiny": {
    "path": "segmind/tiny-sd",
    "preview": "segmind--tiny-sd.jpg"
  },
  "LCM Dreamshaper 7": {
    "path": "SimianLuo/LCM_Dreamshaper_v7",
    "preview": "simianluo--lcm_dreamshaper_v7.jpg"
  },
  "Pixart-α XL 2 Medium": {
    "path": "PixArt-alpha/PixArt-XL-2-512x512",
    "preview": "pixart-alpha--pixart-xl-2-512x512.jpg"
  },
  "Pixart-α XL 2 Large": {
    "path": "PixArt-alpha/PixArt-XL-2-1024-MS",
    "preview": "pixart-alpha--pixart-xl-2-1024-ms.jpg"
  },
  "Warp Wuerstchen": {
    "path": "warp-ai/wuerstchen",
    "preview": "warp-ai--wuerstchen.jpg"
  },
  "Kandinsky 2.1": {
    "path": "kandinsky-community/kandinsky-2-1",
    "preview": "kandinsky-community--kandinsky-2-1.jpg"
  },
  "Kandinsky 2.2": {
    "path": "kandinsky-community/kandinsky-2-2-decoder",
    "preview": "kandinsky-community--kandinsky-2-2-decoder.jpg"
  },
  "DeepFloyd IF Medium": {
    "path": "DeepFloyd/IF-I-M-v1.0",
    "preview": "deepfloyd--if-i-m-v1.0.jpg"
  },
  "Tsinghua UniDiffuser": {
    "path": "thu-ml/unidiffuser-v1",
    "desc": "UniDiffuser is a unified diffusion framework to fit all distributions relevant to a set of multi-modal data in one transformer. UniDiffuser is able to perform image, text, text-to-image, image-to-text, and image-text pair generation by setting proper timesteps without additional overhead.\nSpecifically, UniDiffuser employs a variation of transformer, called U-ViT, which parameterizes the joint noise prediction network. Other components perform as encoders and decoders of different modalities, including a pretrained image autoencoder from Stable Diffusion, a pretrained image ViT-B/32 CLIP encoder, a pretrained text ViT-L CLIP encoder, and a GPT-2 text decoder finetuned by ourselves.",
    "preview": "thu-ml--unidiffuser-v1.jpg"
  }
}
